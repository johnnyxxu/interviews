Staff software enginneer

How to build resilient backend services?
1. set proper time out: to avoid hanging thread or indefinite access to DB
2. have proper fallback: have fallback instances in case of main nodes failure, both services and DB
3. have proper database distribution: deploy DB in multiple regions, backup daily
4. use cache properly: can front load cache to ease main DB access or use it as fall back for graceful shotdown, instead of sudden death
5. circuit breaker for downstreams: to avoid chain reaction of crashing downstream services. 
6. have exponential retries: configure retries with exponential backoff 
7. add proper monitoring: proactively monitor the SLA and error rate to avoid disasater situation
8. practice chaos engineering in controlled situation: bring down downstream service 
9. do load testing: use k6 tools to stress test the system
10. learn from failures. 
11. utilize queues for different async process: to ease load of main service for async process. or use it to catch 5XX scenario to replay the messages after the system is backup
12. add proper load balancer and rate limiter: to decouple different endpoints and better controll individually
13. promote degradation design: gracefully shutdown instead of total error out. ie show shorter feeds instead of failing entirely.

How to make the service scalable? 
1. horizontal scale: add more instances or DB different regions
2. vertical scale: add more memory to the service or DB
3. keey things simple: neccessary logging not overbearing, centralize business logic and not littered with if statements
4. add comprehensive monitoring: little upfront cost, but you can't improve something if not measured
5. improve what's actually needed, not prematurely scale the system.
6. use solid, proven tech: use battle proven tech, not neccessary newest or sexiest tech. 

Examples: 
Start simple, scale deliberately, and don't solve problems you don't have yet. This core philosophy powered Instagram from a single server to serving 1 billion users with just 6 engineers at the time of their Facebook acquisition. 
Netflix took 7 years to fully migrate to microservices, Cortex
Your database is almost always the first scalability bottleneck and the hardest to change later. Instagram's choice of PostgreSQL proved remarkably durableâ€”they still use it as their primary data store today, augmented by Cassandra for specific high-write use cases
